{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f8e82b",
   "metadata": {},
   "source": [
    "# Transfer Learning for BigEarthNet Model with Multispectral Images\n",
    "\n",
    "This notebook holds the code to use a BigEarthNet classifier originally trained by U Berlin and BIFOLD for transfer learning with a custom classifier. This code is in pytorch lighting, since the original model was trained in pytorch.\n",
    "\n",
    "[BIFOLD huggingface repo](https://huggingface.co/BIFOLD-BigEarthNetv2-0/convmixer_768_32-s2-v0.2.0)\n",
    "\n",
    "Resources: pytorch lighting documentation and chatgpt.\n",
    "\n",
    "To download the model, create a wandb account (academic).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ba165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install configilm\n",
    "%pip install wandb\n",
    "%wandb login\n",
    "#Paste api key into terminal and hit enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4daa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import EuroSAT\n",
    "from torchmetrics.classification import Accuracy\n",
    "import pytorch_lightning as pl\n",
    "from reben_publication.BigEarthNetv2_0_ImageClassifier import BigEarthNetv2_0_ImageClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af711e5f",
   "metadata": {},
   "source": [
    "Uncomment for running on mac (m series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c311553",
   "metadata": {},
   "source": [
    "Uncomment for running on cuda gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dde365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0de36c",
   "metadata": {},
   "source": [
    "## Load the datasets into torch dataloaders\n",
    "These will process and supply the model with batches as it trains to conserve memory use. First create a custom dataset class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms data into torch tensors \n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load the full dataset (13 bands) | Set download to False once downloaded\n",
    "dataset = EuroSAT(root=\"data\", bands=\"all\", download=True, transform=transform)\n",
    "\n",
    "# Split into train/val/test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420277e",
   "metadata": {},
   "source": [
    "## Visualize data\n",
    "\n",
    "Take sample from the dataset and visualize it's RGB bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample from the train set and visualize its RGB bands\n",
    "sample_img, sample_label = train_dataset[0]  # or any index\n",
    "\n",
    "# EuroSAT returns images as [C, H, W] tensors; for RGB, use bands 0, 1, 2\n",
    "rgb_img = sample_img[:3].permute(1, 2, 0)  # [H, W, C] for matplotlib\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "plt.title(f\"Label: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79c0df",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigEarthNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_target_classes=5, dropout_rate=0.15):\n",
    "        super().__init__()\n",
    "        # Load pretrained model\n",
    "        self.backbone = BigEarthNetv2_0_ImageClassifier.from_pretrained(\n",
    "            \"BIFOLD-BigEarthNetv2-0/convmixer_768_32-s2-v0.1.1\")\n",
    "        # Freeze backbone classifier remains trainable\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Remove classifier level \n",
    "        print(self.backbone) # check that is actually has a classifier layer\n",
    "        num_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # Create new classifier \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(num_features, num_target_classes) # Input: num_features Output: num_target_classes\n",
    "        \n",
    "        # Define loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Define accuracy metric  \n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_target_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=num_target_classes)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=num_target_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        x = self.dropout(features)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7a56a",
   "metadata": {},
   "source": [
    "## Run training loop for classifier\n",
    "Once the model is assembled we use the following code to train the classifier level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigEarthNetClassifier() # Create an instance of the model\n",
    "trainer = pl.Trainer() # Create a pytorch lighting trainer\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader) # Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83aed2",
   "metadata": {},
   "source": [
    "## Test model\n",
    "Load the model and run it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigEarthNetClassifier.load_from_checkpoint(PATH)\n",
    "model.freeze() # makes the model read-only for inference.\n",
    "predictions = trainer.predict(model, dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
