{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c03c540",
   "metadata": {},
   "source": [
    "# Transfer Learning for VGG16 Model with RGB\n",
    "\n",
    "This notebook includes code for finetunning a VGG16 model for classification with Keras on the RGB version of the eurosat dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on mac GPU\n",
    "# %pip install tensorflow-macos tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe0b96",
   "metadata": {},
   "source": [
    "## Preprocess images \n",
    "Download the RGB version of the eurosat database from tensorflow.datasets. Dataset includes 27,000 examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EuroSAT dataset\n",
    "ds, ds_info = tfds.load('eurosat', split='train', with_info=True, as_supervised=True)\n",
    "total = 27000\n",
    "train_size = int(0.8*total)\n",
    "val_size = int(0.1*total)\n",
    "test_size = total - train_size - val_size\n",
    "\n",
    "train_dataset = ds.take(train_size)\n",
    "train_labels = ds_info.take(train_size)\n",
    "val_dataset = ds.take(val_size)\n",
    "val_labels = ds.take(val_size)\n",
    "test_dataset = ds.take(test_size)\n",
    "test_labels = ds_info.take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa749e6b",
   "metadata": {},
   "source": [
    "Visualize an image from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9388a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in ds.take(1):\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    plt.title(f\"Label: {label.numpy()}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831db517",
   "metadata": {},
   "source": [
    "Preprocess the datasets to match the image size expected from VGG16.\n",
    "\n",
    "1. Resizes the image to (224, 224) pixels, which is the input size expected by VGG16.\n",
    "\n",
    "2. Applies preprocess_input from tensorflow.keras.applications.vgg16, which: \n",
    "    - converts the image to float32\n",
    "    - Changes the color channel order from RGB to BGR\n",
    "    - Subtracts the mean pixel values (specific to ImageNet: [103.939, 116.779, 123.68] for B, G, R channels).\n",
    "3. Applies prefetch autotune, which allows tensorflow to prepare the next batch as the current one is loading for max efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0de357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))  # match VGG16 input size\n",
    "    image = preprocess_input(tf.cast(image, tf.float32))\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9ec65",
   "metadata": {},
   "source": [
    "## Fine-tune model \n",
    "\n",
    "Load the model (in this case VGG16 trained on imagenet) and extract it's convolutional base. These are the layers that extract the features from the images. \n",
    "\n",
    "We then freeze these layers from training and plug in a new classifier layer at the end with a custom number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the convolutional layers from the VGG16 model and configure to needs. \n",
    "conv_base = tf.keras.applications.VGG16(weights='imagenet', \n",
    "                                        include_top=False, \n",
    "                                        input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f40e94",
   "metadata": {},
   "source": [
    "The preprocess_input function ensures satellite images are formatted correctly so the model can extract meaningful features. It iterates over all the batches and returns two numpy arrays:   \n",
    "\n",
    "1) The features, whose shape depends on the output of your conv_base (Samples, Height, Width, Channels).\n",
    "\n",
    "2) The labels, which are stored in a one-dimensional array or two-dimensional (if one‐hot encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca04fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset, conv_base):\n",
    "    conv_base.trainable = False\n",
    "    processed_images = preprocess_input(dataset)\n",
    "    return processed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73891a3",
   "metadata": {},
   "source": [
    "Now build the classifier layers that go ontop of the frozen convolutional base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_model(input_shape= train_features.shape[1:]): #input shape is (height, width, channels) because keras is agnostic to batch size\n",
    "\n",
    "    inputs = keras.Input(shape=(input_shape))\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss='sparse_crossentropy', # for non-binary tasks \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b070c",
   "metadata": {},
   "source": [
    "Run the model and visualize the loss and accuracy throughout the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d34f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = build_dense_model(input_shape=train_dataset.shape[1:])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "      filepath=\"feature_extraction.keras\",\n",
    "      save_best_only=True,\n",
    "      monitor=\"val_loss\")\n",
    "]\n",
    "history = dense_model.fit(\n",
    "    train_dataset, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_dataset, val_labels),\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c9d0b",
   "metadata": {},
   "source": [
    "## Test model \n",
    "Evaluate on test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456186a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.evaluate(test_dataset, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
